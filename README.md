## Project|Work Showcase
---
```
This README is to showcase projects I've previously made, as well as scripts and code I use in my daily worklife.
To view a list of my skillset, please visit either my linkedin or my resume application. Both links are offered below:
```
[linkedin profile](https://www.linkedin.com/in/derek-westjohn-82154662)
[resume application](placeholderforresumewebsite)




### Machine Learning
---
![covid_gif](github.com/dwest85/project_showcase/blob/main/markdown_gifs/covid19_gif.gif)

[Covid-19 Prediction Application Link - Hosted on Heroku](https://covidappproject.herokuapp.com/)

###### Description:
This application was built with the streamlit framework, using the Python language as the core building block. The pandas package was used in Jupyter Notebook for the majority of the data cleaning|processing and the sci-kit learn and scipy packages were used for building the machine learning element for the supervised learning application. Logistic Regression and Ridge Regression was the model and argument, which achieved an 89% accuracy score. Pickle was also used for the encoding process for the application.

Using the different parameters, the application will predict the death probability and surviving probability based on the socio-economic traits selected. The application also further explains the power of Ridge Regression and it's use to achieve the strong accuracy score. The code for this application can be found in the covid_prediction_application folder.



### Dashboards and APIs
---
![excel_dashboard_gif](https://github.com/dwest85/project_showcase/blob/main/markdown_gifs/dashboard_gif.gif)

###### Description:
I create and use dashboards weekly for my current company to create insight and build upon the progression of our company goals. The dashboards showcased above were custom built in Excel due to the data used being very compartmentalized and unprocessed|dirty. The reporting is pulled in from all over using an ETL pipline process and then using Python automation and Power Query for the updating process. Some of the processing examples for these dashboards can be found in the data_processing_wrangling_code folder. I also create dashboards using other platforms, such as Tableau and PowerBI.

I also use the Google Maps API frequently to incorporate competitor data into the dashboards for strategy based decisions and goals.



### Visualizations
---
![tableau_reports_gif](https://github.com/dwest85/project_showcase/blob/main/markdown_gifs/visuals_gif.gif)

###### Description:
I often create weekly visual reporting for our clientele using Tableau and Constant Contacts, but have used the following packages and platforms to also create visual insight: PowerBI, matplotlib, seaborn, plotly, ggplot2, altair, etc.



### Python Automation|Scripts
---
![scriptsgif](https://github.com/dwest85/project_showcase/blob/main/markdown_gifs/automation_gif.gif)

###### Description:
I often use Python based automation to help speed up productivity and precision throughout my work week. These small scripts are used for email chains, automated file structuring, data scraping, and many other uses. I also weave Batch and Powershell into the mix when automatiing certain objectives. 



### Database Storage|Use
---
![databaseimg1](https://github.com/dwest85/project_showcase/blob/main/markdown_images/databaseimg1.jpg)

![databaseimg2](https://github.com/dwest85/project_showcase/blob/main/markdown_images/databaseimg2.jpg)

###### Description:
I often use Postgres and SQL servers, such as AWS|Heroku to assist with proper file storage and data transfers. Creating a data warehouse is vital for data cleaning|processing.



